{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattiadg2001/Machine-Learning-Labs/blob/main/Copy_of_ML2025_01_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-d_quaie4Pj"
      },
      "source": [
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6giCMiZfHuy"
      },
      "source": [
        "## The Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cZWyGYHbGyy"
      },
      "source": [
        "Let us consider the [iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n",
        "\n",
        "In the dataset we have data regarding specific species of flowers :\n",
        "- Sepal length;\n",
        "- Sepal width;\n",
        "- Petal length;\n",
        "- Petal width;\n",
        "- Species (*Iris setosa*, *Iris virginica* e *Iris versicolor*).\n",
        "\n",
        "In the specific, we have N = 150 total samples (50 per class).\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1cBVClKfJOVXwK-VCjwd9XzRgCN-wvec_' width=250>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFiMVDR4ee8Y"
      },
      "source": [
        "We need to import **matplotlib** and **pandas** to handle data and plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n58XRpsX2cfv"
      },
      "source": [
        "import pandas as pd #https://pandas.pydata.org/\n",
        "from pandas.plotting import scatter_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import axes3d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsTZ7gaOe0-X"
      },
      "source": [
        "We can find the dataset we need to analyse online. We use pandas to load the csv to a **pandas.DataFrame**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsDXGniMhFHO"
      },
      "source": [
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
        "dataset = iris_dataset = pd.read_csv(url, names=names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cuX00NpfKfQ"
      },
      "source": [
        "We can start to have a look the data we have"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ6dMKw4hMG8",
        "collapsed": true
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7QPbBXcfxJR"
      },
      "source": [
        "we do not care about the flower species in this lesson, hence we remove that column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NwQ3wkKxCMK"
      },
      "source": [
        "dataset = dataset.drop('class', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2mK3dX4qtyp"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsNZl40AgQJz"
      },
      "source": [
        "We will try to understand how the feature are distributed, by printing some statistics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wZg_9XsjX26"
      },
      "source": [
        "dataset.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEQ7UCiShR8r"
      },
      "source": [
        "Visualizing data can also be very helpful:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm6vr21oki0W"
      },
      "source": [
        "dataset.hist(figsize=(16,9))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z4dN_xkktbf"
      },
      "source": [
        "scatter_matrix(dataset, figsize=(16, 9))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bm7JLrwnhqoM"
      },
      "source": [
        "*petal-lenght* and *petal-width* seem to have a strong relationship... we should investigate it more in detail!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdIV99sFxuzy"
      },
      "source": [
        "dataset.plot.scatter('petal-length', 'petal-width', grid=True, figsize=(16,9))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9D0uEbnoKjL"
      },
      "source": [
        "# Predicting Petal Width from Petal Length"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preprocessing"
      ],
      "metadata": {
        "id": "2IPVkqV6xCiO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go8xsLbNiSvM"
      },
      "source": [
        "Once we inspected the data, we should operate some preprocessing procedures. On a\n",
        "generic dataset one should perform:\n",
        "\n",
        "- shuffling;\n",
        "- remove inconsistent data;\n",
        "- remove outliers;\n",
        "- normalize or standardize data;\n",
        "- fill missing data.\n",
        "\n",
        "In this case we are going to use the entire dataset, with a non-iterative method, hence we do not need to **shuffle**.\n",
        "\n",
        "There seems not to be **outliers** from previous inspection.\n",
        "\n",
        "Is there any **missing data**?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edbi7OwnkpH0"
      },
      "source": [
        "import numpy as np #https://numpy.org/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG5zNjjgkulp"
      },
      "source": [
        "np.any(np.isnan(dataset.values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfRSP-95k4RX"
      },
      "source": [
        "we are lucky, no missing data, no outliers...\n",
        "\n",
        "However it is always better to work with data in the same scale, hence we should normalize the columns we are going to use.\n",
        "\n",
        "\\begin{align*}\n",
        "\ts &\\leftarrow \\frac{s - \\bar{s}}{S} \\\\\n",
        "\ts &\\leftarrow \\frac{s - \\min_n \\{ s_n \\}}{\\max_n \\{ s_n \\} - \\min_n \\{ s_n \\}}\n",
        "\\end{align*}\n",
        "\n",
        "The **zscore** function operates a standardization of its inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK0h49LloI-0"
      },
      "source": [
        "from scipy.stats import zscore #https://scipy.org/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0QkTCpxsyKg"
      },
      "source": [
        "x = zscore(dataset['petal-length'].values).reshape(-1, 1) # we reshape our feature column as a (n_sample, n_features) matrix\n",
        "y = zscore(dataset['petal-width'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "fkk---GXjL4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(x)"
      ],
      "metadata": {
        "id": "vDmI-heFreyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.std(x)"
      ],
      "metadata": {
        "id": "QaDliPnf7Qql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYB11a3go4AW"
      },
      "source": [
        "## Using Scikit-Learn Toolbox"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCDdGvUGl1O2"
      },
      "source": [
        "A linear model seems to be a good choice to predict *petal-width* given petal-length, let's use **scikit-learn** tools to do a linear regression:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0aTBQocn5tI"
      },
      "source": [
        "from sklearn import linear_model #https://scikit-learn.org/stable/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIh9maFIoQWQ"
      },
      "source": [
        "lin_model = linear_model.LinearRegression()\n",
        "lin_model.fit(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lin_model.coef_"
      ],
      "metadata": {
        "id": "gwmG_dZBuj_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lin_model.intercept_"
      ],
      "metadata": {
        "id": "EhhN8kCku19A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLRcm1MPmn3I"
      },
      "source": [
        "since we want to customize our plot, we will use matplotlib directly this time:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0FnjJjYt6tS"
      },
      "source": [
        "plt.figure(figsize=(16,9))\n",
        "plt.scatter(x, y, label='true')\n",
        "\n",
        "w1 = lin_model.coef_ # weights of the model are stored here\n",
        "w0 = lin_model.intercept_ # and here it is the intercept\n",
        "\n",
        "# Compute the y component of the regression line\n",
        "\n",
        "y_pred = lin_model.predict(x)\n",
        "#y_pred = [w1 * sample + w0 for sample in x.flatten()]\n",
        "\n",
        "# (we used a list comprehension here, have a look to the python tutorial\n",
        "#  if you don't know what it is!)\n",
        "\n",
        "plt.plot(x, y_pred, label='predicted', color='red')\n",
        "\n",
        "# enlarging fonts\n",
        "plt.legend(prop={'size': 20})\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics"
      ],
      "metadata": {
        "id": "2y1CBkNPsEvc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k3XhIyq6zjk"
      },
      "source": [
        "To evaluate the quality of our regression we can analyse some metrics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM7hyv5VuA-J"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6PxpJIy9sEh"
      },
      "source": [
        "### Residual Sum of Squares\n",
        "\n",
        "$RSS = \\sum_n (\\hat{t}_n-t_n)^2$, it tells us how much of the prediction differs from the true value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NefO1wGd_ZW4"
      },
      "source": [
        "RSS = np.sum((y_pred-y)**2)\n",
        "RSS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9WRg42r9COM"
      },
      "source": [
        "### Coefficient of determination\n",
        "\n",
        "$R^2 = 1 - \\frac{RSS}{\\sum_n (\\bar{t}-t_n)^2}$, it tells us how the fraction of the variance of the data explained by the model (how much better we are doing w.r.t. just using the mean of the target $\\bar{t} = \\frac{\\sum_n t_n}{N}$).\n",
        "\n",
        "In spaces with a single feature this is equal to the correlation coefficient between the input and the output;\n",
        "\n",
        "For a more detailed explanation: https://en.wikipedia.org/wiki/Coefficient_of_determination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "320Lw_LDv55f"
      },
      "source": [
        "r2_score(y, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXBmBYQS7kJJ"
      },
      "source": [
        "### Mean Squared Error\n",
        "\n",
        "$MSE = \\frac{\\sum_n (\\hat{t}_n-t_n)^2}{N}$, it tells approximately how much error we get on a predicted data over the training set (i.e., a normalized version of the RSS)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFTip4m7vriY"
      },
      "source": [
        "mean_squared_error(y, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Significance tests"
      ],
      "metadata": {
        "id": "Wm0OmYfGs06y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikyuzWZCUZmy"
      },
      "source": [
        "Under the assumption that the observations $t_n$ are i.i.d. and satisfies $t_n = w_0 + \\sum_j w_j x_{nj} + \\epsilon$, where $\\epsilon$ is a Gaussian noise with zero mean and variance $\\sigma^2$ (i.e., the data are generated by a linear model with noise), the computed coefficients $\\hat{w}_j$ are distributed as follows:\n",
        "\\begin{equation*}\n",
        "\t\\frac{\\hat{w}_j - w_j}{\\hat{\\sigma} \\sqrt{v_j}} \\sim t_{N - M -1}\n",
        "\\end{equation*}\n",
        "where $w_j$ is the true parameter, $\\hat{\\sigma}$ is the unbiased estimated for the target variance, i.e., $\\hat{\\sigma}^2 = \\frac{\\sum_n (t_n - \\hat{t}_n)^2}{N - M - 1}$, $v_j$ is the $j$-th diagonal element of the matrix $(X^T X)^{-1}$ and $t_{N - M-1}$ is the t-student distribution with $N - M - 1$ degrees of freedom.\n",
        "\n",
        "This allow us to formulate some **statistical tests**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYdRoIWvLsAG"
      },
      "source": [
        "### Single coefficients statistical test:\n",
        "$$H_0: w_j = 0 \\qquad \\text{ vs. } \\qquad H_1: w_j \\neq 0$$\n",
        "\\begin{equation*}\n",
        "t_{stat} = \\frac{\\hat{w}_j - w_j}{\\hat{\\sigma} \\sqrt{v_j}} \\sim t_{N - M - 1}\n",
        "\\end{equation*}\n",
        "where $t_{N - M - 1}$ is the T-Student distribution with $N-M-1$ degrees of freedom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIh8kFzOBm5P"
      },
      "source": [
        "### Overall significance of the model: F-statistic\n",
        "\n",
        "It considers the following hypothesis test:\n",
        "\n",
        "$$H_0: w_1 = \\dots = w_M = 0 \\text{ vs. }  H_1: \\exists w_j \\neq 0$$\n",
        "\n",
        "\n",
        "The F-statistic can be computed and is distributed as follows:\n",
        "$$ F = \\frac{dfe}{M }\\frac{\\sum_n (\\overline{t}_n-t_n)^2- RSS}{RSS} \\sim F_{M, N-M-1} $$\n",
        "\n",
        "where $F_{M, N-M-1}$ is the Fisher-Snedecor distribution with parameters $M$ and $N-M-1$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68YdCO_YFNjQ"
      },
      "source": [
        "If one wants all the information about the output of a linear model in a single instruction, just use the library **statsmodels** and use the function **summary()** on the result of the Ordinary Least Square optimization procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBi56iByBGL-"
      },
      "source": [
        "from statsmodels import api as sm\n",
        "lin_model = sm.OLS(y, x).fit()\n",
        "print(lin_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3xbvcYLy1b3"
      },
      "source": [
        "lin_model._results.params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMgH_0AmzF2Z"
      },
      "source": [
        "lin_model._results.k_constant"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TODO:** Predicting Sepal Length"
      ],
      "metadata": {
        "id": "tA_yE7LjqhiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It was easy to predict petal width from petal length alone:\n",
        "\n",
        "$$\\hat{y} = w_0 + w_1 \\cdot \\mathrm{petal\\_length}$$\n",
        "\n",
        "Now you face a more challenging problem: predicting **sepal length** from the other variables (petal length, petal width, sepal width). There are many things you can do.\n",
        "\n",
        "You can choose one among petal length, petal width, sepal width and re-use the solution above for single-input single-output linear regression.\n",
        "\n",
        "You can use two or all of your input variables:\n",
        "\n",
        "$$\\hat{y} = w_0 + w_1 \\cdot \\mathrm{petal\\_length} + w_2 \\cdot \\mathrm{petal\\_width} + w_3 \\cdot \\mathrm{sepal\\_width} = \\sum_{i=0}^3w_i x_i = \\mathbf{w}^\\top \\mathbf{x}$$\n",
        "\n",
        "$\\mathbf{x} = [1,\\mathrm{petal\\_length}, \\mathrm{petal\\_width}, \\mathrm{sepal\\_width}]^\\top$.\n",
        "\n",
        "You can consider even more complex models by introducing any set of **features** (arbitrary functions) of the input variables\n",
        "\n",
        "\n",
        "\n",
        "Example:\n",
        "\n",
        "* $\\phi_1(\\mathbf{x}) = \\mathrm{petal\\_length}$\n",
        "* $\\phi_2(\\mathbf{x}) = \\mathrm{petal\\_length^2}$\n",
        "* $\\phi_3(\\mathbf{x}) = \\mathrm{petal\\_width}\\cdot \\mathrm{sepal\\_width}$\n",
        "* ...\n",
        "\n",
        "$$\\hat{y} = w_0 + w_1 \\cdot \\phi_1(\\mathbf{x}) + w_2 \\cdot \\phi_2(\\mathbf{x}) + \\dots + w_d\\cdot\\phi_d(\\mathbf{x}) = \\sum_{i=0}^dw_i \\phi_i(\\mathbf{x})  = \\mathbf{w}^\\top\\mathbf{\\phi}(\\mathbf{x})$$\n",
        "\n",
        "\n",
        "where $\\mathbf{\\phi}(\\mathbf{x})= [1, \\phi_1(\\mathbf{x}), \\phi_2(\\mathbf{x}),\\dots,\\phi_d(\\mathbf{x})]^\\top$"
      ],
      "metadata": {
        "id": "QKlsoH-H0W2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some useful snippets first\n",
        "# How to extract multiple columns from a dataframe:\n",
        "X = dataset[[\"petal-width\", \"sepal-width\"]]\n",
        "assert X.shape == (150, 2) # no need to add a \"fake\" second dimension this time\n",
        "# How to normalize each column separately:\n",
        "X = zscore(X, axis=1)\n",
        "# How to stack numpy arrays along a new axis\n",
        "x_1 = np.ones(4)\n",
        "x_2 = np.zeros(4)\n",
        "xx = np.stack((x_1, x_2), axis=1)\n",
        "assert xx.shape == (4,2)\n",
        "# How to concatenate numpy arrays along an existing axis\n",
        "z_1 = np.ones((4, 1))\n",
        "z_2 = np.zeros((4, 1))\n",
        "zz = np.concatenate((z_1, z_2), axis=1)\n",
        "assert zz.shape == (4, 2)\n",
        "\n",
        "### WRITE YOUR CODE HERE ###\n"
      ],
      "metadata": {
        "id": "EZTrpmIdJJY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thought Experiment"
      ],
      "metadata": {
        "id": "CbE26jc4C0xR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model that we train depends on the specific dataset that we have. The Iris dataset was collected by American botanist Edgar Anderson in the 1930s.  \n",
        "How representative is it of the population of Iris flowers? Maybe Anderson was just lucky to find flowers following a particular law...\n",
        "\n",
        "Like Anderson, we go into the wild and measure the petal length (x) and sepal length (y) of Iris flowers.\n",
        "\n",
        "First we collect 50 flowers and set them apart for testing purposes.\n",
        "\n",
        "Then, each day we collect a different dataset of 20 flowers and fit two models using linear regression to predict **sepal length from petal length**:\n",
        "\n",
        "* A \"simple\" linear model where the only feature is x itself\n",
        "* A \"complex\" polynomial model with $\\mathbf{\\phi} = [x, x^2]^\\top$"
      ],
      "metadata": {
        "id": "ADqz0n2FFaZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_dataset(n=20):\n",
        "  # Pretend this is the secret Nature's distribution of Iris flowers\n",
        "  return dataset.sample(n)"
      ],
      "metadata": {
        "id": "6YW97UuDoXvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our test data\n",
        "test_data = sample_dataset(n=50)\n",
        "x_test = zscore(test_data['petal-length'].values)\n",
        "y_test = zscore(test_data[\"sepal-length\"].values)\n",
        "\n",
        "plt.scatter(x_test, y_test)"
      ],
      "metadata": {
        "id": "u8kFDC1K0uyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repetitions = 1000\n",
        "m1 = linear_model.LinearRegression()\n",
        "mse_1 = np.zeros(repetitions)\n",
        "\n",
        "m2 = linear_model.LinearRegression()\n",
        "mse_2 = np.zeros(repetitions)\n",
        "\n",
        "def feature_map(x, d=2):\n",
        "  return np.stack([x**i for i in range(1, d+1)], axis=1)\n",
        "\n",
        "for i in range(repetitions):\n",
        "  dat = sample_dataset()\n",
        "  x = zscore(dat['petal-length'].values)\n",
        "  y = zscore(dat[\"sepal-length\"].values)\n",
        "\n",
        "  m1.fit(x.reshape(-1, 1), y)\n",
        "  y_1 = m1.predict(x_test.reshape(-1, 1))\n",
        "  mse_1[i] = mean_squared_error(y_test, y_1)\n",
        "\n",
        "  m2.fit(feature_map(x), y)\n",
        "  y_2 = m2.predict(feature_map(x_test))\n",
        "  mse_2[i] = mean_squared_error(y_test, y_2)"
      ],
      "metadata": {
        "id": "nzyaXCaopOTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Which model is better?"
      ],
      "metadata": {
        "id": "vi856Oz18oi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"M1: mean of MSEs=\", np.mean(mse_1), \", std of MSEs=\", np.std(mse_1))\n",
        "print(\"M2: mean of MSEs=\", np.mean(mse_2), \", std of MSEs=\", np.std(mse_2))"
      ],
      "metadata": {
        "id": "y1hykgoM8itp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,9))\n",
        "\n",
        "plt.scatter(zscore(dataset['petal-length'].values),\n",
        "            zscore(dataset['sepal-length'].values),\n",
        "            alpha=0.7)\n",
        "\n",
        "for _ in range(20):\n",
        "  dat = sample_dataset()\n",
        "  x = zscore(dat['petal-length'].values)\n",
        "  y = zscore(dat[\"sepal-length\"].values)\n",
        "\n",
        "  m1.fit(x.reshape(-1, 1), y)\n",
        "  m2.fit(feature_map(x), y)\n",
        "\n",
        "  #plt.scatter(x, y, label='true')\n",
        "\n",
        "  w1 = m1.coef_\n",
        "  w0 = m1.intercept_\n",
        "\n",
        "  xx = np.linspace(min(x_test), max(x_test), 100)\n",
        "  yy = m2.predict(feature_map(xx))\n",
        "  plt.plot(xx, w0 + w1 * xx, \"r--\", alpha=0.3)\n",
        "  plt.plot(xx, yy, color='orange', alpha=0.3)\n",
        "\n",
        "plt.legend(prop={'size': 20})\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6kog1FW3RCuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.boxplot((mse_1, mse_2));"
      ],
      "metadata": {
        "id": "DV-Iier1Kp-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In practice we (typically) have just one dataset!\n",
        "We will see how to choose the best model in following lectures..."
      ],
      "metadata": {
        "id": "rTt-f4swIoao"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNhAGwb4Iyso"
      },
      "source": [
        "# Homeworks\n",
        "\n",
        "Here we propose some exercises in python for you. They are not mandatory, but they can be helpful to better understand the contents of the lecture, by giving you the opportunity to develop some code by yourself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhYMNJakoxBa"
      },
      "source": [
        "### 1) Custom Implementation\n",
        "\n",
        "We can also implement Least-Squares from scratch, using its closed-form:\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{\\mathbb{w}}_{OLS} = (\\mathbb{\\Phi}^{\\top}\\mathbb{\\Phi})^{-1}\\mathbb{\\Phi}^{\\top}\\ \\mathbb{t},\n",
        "\\end{equation}\n",
        "\n",
        "where $\\mathbb{\\Phi}= (\\phi(x_1), \\dots, \\phi(x_N))^{\\top}$ and $\\mathbb{t} = (t_1, \\dots, t_N)^{\\top}.$\n",
        "\n",
        "By using **numpy**:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkjL1BgVI6qn"
      },
      "source": [
        "from numpy.linalg import inv\n",
        "\n",
        "### WRITE YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B_rKvZItg6P"
      },
      "source": [
        "### 2) Implementing LS for multiple outputs\n",
        "\n",
        "We have seen at lesson that LS is possible also when we have multiple outputs.\n",
        "\n",
        "Implement it by extending the LS custom implementation that we have seen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOzCW5qXtr-1"
      },
      "source": [
        "### WRITE YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7jiEl88tByT"
      },
      "source": [
        "### 3) Try it on another dataset\n",
        "\n",
        "Try to repeat the procedure that we have seen for the Iris dataset on a new dataset of your choice:\n",
        "\n",
        "- select a dataset (many are available online, e.g. https://www.kaggle.com/datasets)\n",
        "- visualize data, in order to spot interesting relationships\n",
        "- preprocess data\n",
        "- apply linear regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs2jRanHtfgs"
      },
      "source": [
        "### WRITE YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}